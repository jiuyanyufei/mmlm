# å¤šæ¨¡æ€å¤§æ¨¡å‹ (Multimodal Large Language Model)

## ğŸš€ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåŸºäºçº¯è§£ç å™¨æ¶æ„çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œæ”¯æŒ**ä»»æ„å½¢æ€çš„è¾“å…¥**å’Œ**ä»»æ„æ¨¡æ€çš„è¾“å‡º**ã€‚æ¨¡å‹èƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å†³å®šè¾“å‡ºå“ªç§æ¨¡æ€ï¼Œå®ç°çœŸæ­£çš„è·¨æ¨¡æ€ç”Ÿæˆèƒ½åŠ›ã€‚

### ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **ä»»æ„è¾“å…¥æ¨¡æ€**: æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘
- **ä»»æ„è¾“å‡ºæ¨¡æ€**: æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘  
- **æ¨¡æ€è‡ªé€‚åº”**: æ¨¡å‹è‡ªåŠ¨å­¦ä¹ è¾“å…¥è¾“å‡ºæ¨¡æ€å…³ç³»
- **ç»Ÿä¸€æ¶æ„**: çº¯è§£ç å™¨è®¾è®¡ï¼Œæ— éœ€å¤æ‚ç¼–ç å™¨-è§£ç å™¨ç»“æ„
- **ç«¯åˆ°ç«¯è®­ç»ƒ**: æ‰€æœ‰æ¨¡æ€ç»Ÿä¸€è®­ç»ƒï¼Œæ— éœ€åˆ†é˜¶æ®µè®­ç»ƒ

## ğŸ“Š æ¨¡æ€æ”¯æŒçŸ©é˜µ

| è¾“å…¥æ¨¡æ€ | æ–‡æœ¬è¾“å‡º | å›¾åƒè¾“å‡º | è§†é¢‘è¾“å‡º | éŸ³é¢‘è¾“å‡º |
|---------|---------|---------|---------|---------|
| **æ–‡æœ¬** | âœ… æ–‡æœ¬â†’æ–‡æœ¬ | âœ… æ–‡æœ¬â†’å›¾åƒ | âœ… æ–‡æœ¬â†’è§†é¢‘ | âœ… æ–‡æœ¬â†’éŸ³é¢‘ |
| **å›¾åƒ** | âœ… å›¾åƒâ†’æ–‡æœ¬ | âœ… å›¾åƒâ†’å›¾åƒ | âœ… å›¾åƒâ†’è§†é¢‘ | âœ… å›¾åƒâ†’éŸ³é¢‘ |
| **è§†é¢‘** | âœ… è§†é¢‘â†’æ–‡æœ¬ | âœ… è§†é¢‘â†’å›¾åƒ | âœ… è§†é¢‘â†’è§†é¢‘ | âœ… è§†é¢‘â†’éŸ³é¢‘ |
| **éŸ³é¢‘** | âœ… éŸ³é¢‘â†’æ–‡æœ¬ | âœ… éŸ³é¢‘â†’å›¾åƒ | âœ… éŸ³é¢‘â†’è§†é¢‘ | âœ… éŸ³é¢‘â†’éŸ³é¢‘ |

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç»Ÿä¸€Tokenæµæ¶æ„

```
è¾“å…¥æ¨¡æ€ â†’ æ¨¡æ€ç¼–ç å™¨ â†’ ç»Ÿä¸€Tokenåºåˆ— â†’ Transformerè§£ç å™¨ â†’ æ¨¡æ€è§£ç å™¨ â†’ è¾“å‡ºæ¨¡æ€
```

### æ ¸å¿ƒç»„ä»¶

1. **å¤šæ¨¡æ€Tokenizer**
   - æ–‡æœ¬: GPT-2 Tokenizer
   - å›¾åƒ: ViTç‰¹å¾æå– + é‡åŒ–
   - éŸ³é¢‘: Wav2Vec2ç‰¹å¾æå– + é‡åŒ–  
   - è§†é¢‘: å¸§æå– + ViTå¤„ç†

2. **ç»Ÿä¸€GPTæ¨¡å‹**
   - åŸºäºGPT-2æ¶æ„çš„çº¯è§£ç å™¨
   - æ‰€æœ‰æ¨¡æ€å…±äº«å‚æ•°ç©ºé—´
   - è‡ªå›å½’ç”Ÿæˆä»»æ„æ¨¡æ€åºåˆ—

3. **æ¨¡æ€é¢„æµ‹å™¨**
   - å­¦ä¹ è¾“å‡ºæ¨¡æ€ç±»å‹
   - åŠ¨æ€è·¯ç”±åˆ°å¯¹åº”è§£ç å™¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install torch transformers pillow librosa soundfile decord
```

### åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

```python
from models.unified_gpt import UnifiedMultimodalGPT
from models.tokenizers import MultimodalTokenizer
from transformers import GPT2Tokenizer

# åˆå§‹åŒ–ç»„ä»¶
text_tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
multimodal_tokenizer = MultimodalTokenizer(text_tokenizer)
model = UnifiedMultimodalGPT()

# å¤šæ¨¡æ€è¾“å…¥å¤„ç†
inputs = multimodal_tokenizer.tokenize_multimodal(
    text="æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹",
    image="cat.jpg",
    audio="sound.wav"
)

# ç”Ÿæˆå¤šæ¨¡æ€è¾“å‡ºï¼ˆæ¨¡å‹è‡ªåŠ¨å†³å®šè¾“å‡ºæ¨¡æ€ï¼‰
outputs = model.generate(
    input_ids=inputs["input_ids"],
    attention_mask=inputs["attention_mask"],
    max_length=100
)

# è§£ç è¾“å‡º
if model.predict_modality(outputs) == "text":
    generated_text = text_tokenizer.decode(outputs[0])
    print(f"ç”Ÿæˆçš„æ–‡æœ¬: {generated_text}")
elif model.predict_modality(outputs) == "image":
    image = model.decode_image(outputs[0])
    image.save("generated_image.png")
```

### å¼ºåˆ¶æŒ‡å®šè¾“å‡ºæ¨¡æ€

```python
# å¼ºåˆ¶ç”Ÿæˆå›¾åƒè¾“å‡º
outputs = model.generate(
    input_ids=inputs["input_ids"],
    output_modality="image",  # å¼ºåˆ¶æŒ‡å®šè¾“å‡ºæ¨¡æ€
    max_length=50
)
```

### å¤šæ¨¡æ€åˆ°å¤šæ¨¡æ€è½¬æ¢

```python
# æ–‡æœ¬+å›¾åƒ â†’ è§†é¢‘+éŸ³é¢‘
inputs = multimodal_tokenizer.tokenize_multimodal(
    text="åˆ›å»ºä¸€æ®µé…ä¹è§†é¢‘",
    image="background.jpg"
)

outputs = model.generate(
    input_ids=inputs["input_ids"],
    output_modality=["video", "audio"],  # å¤šæ¨¡æ€è¾“å‡º
    max_length=200
)
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
mmlm/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ unified_gpt.py          # ç»Ÿä¸€å¤šæ¨¡æ€GPTæ¨¡å‹
â”‚   â”œâ”€â”€ tokenizers.py          # å¤šæ¨¡æ€Tokenizer
â”‚   â””â”€â”€ decoders.py            # æ¨¡æ€è§£ç å™¨
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processors.py         # æ•°æ®å¤„ç†å™¨
â”‚   â””â”€â”€ dataset.py             # æ•°æ®é›†ç±»
â”œâ”€â”€ config.py                  # é…ç½®æ–‡ä»¶
â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py               # æ¨ç†è„šæœ¬
â”œâ”€â”€ demo_unified.py            # æ¼”ç¤ºè„šæœ¬
â””â”€â”€ README.md                  # é¡¹ç›®è¯´æ˜
```

## ğŸ› ï¸ è®­ç»ƒé…ç½®

### æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®æ”¯æŒçµæ´»çš„æ¨¡æ€é…å¯¹ï¼š

```json
{
    "input": {
        "text": "æè¿°åœºæ™¯",
        "image": "scene.jpg",
        "audio": "background.wav"
    },
    "output": {
        "text": "ç”Ÿæˆçš„æè¿°æ–‡æœ¬",
        "video": "generated.mp4"
    }
}
```

### è®­ç»ƒå‘½ä»¤

```bash
python train.py \
    --train_file data/train.json \
    --output_dir ./outputs \
    --model_name unified_mmlm \
    --per_device_train_batch_size 8 \
    --learning_rate 5e-5 \
    --num_train_epochs 3 \
    --enable_multimodal_output
```

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### æ¨¡æ€ç¼–ç ç­–ç•¥

1. **æ–‡æœ¬æ¨¡æ€**
   - ä½¿ç”¨GPT-2 Tokenizer
   - æœ€å¤§é•¿åº¦: 512 tokens

2. **å›¾åƒæ¨¡æ€**  
   - ä½¿ç”¨ViTæå–ç‰¹å¾
   - å›¾åƒå¤§å°: 224Ã—224
   - Patchå¤§å°: 16Ã—16
   - ç‰¹å¾é‡åŒ–: 10,000è¯æ±‡è¡¨

3. **éŸ³é¢‘æ¨¡æ€**
   - ä½¿ç”¨Wav2Vec2æå–ç‰¹å¾
   - é‡‡æ ·ç‡: 16kHz
   - ç‰¹å¾é‡åŒ–: 10,000è¯æ±‡è¡¨

4. **è§†é¢‘æ¨¡æ€**
   - å¸§æå– + ViTå¤„ç†
   - æœ€å¤§å¸§æ•°: 16
   - æ—¶åºä½ç½®ç¼–ç 

### æ¨¡å‹å‚æ•°

- **éšè—å±‚ç»´åº¦**: 768
- **Transformerå±‚æ•°**: 12
- **æ³¨æ„åŠ›å¤´æ•°**: 12  
- **æœ€å¤§åºåˆ—é•¿åº¦**: 2048
- **æ€»è¯æ±‡è¡¨**: ~70,000 tokens

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

| ä»»åŠ¡ç±»å‹ | å‡†ç¡®ç‡ | ç”Ÿæˆè´¨é‡ |
|---------|--------|----------|
| æ–‡æœ¬â†’æ–‡æœ¬ | 85% | â­â­â­â­â­ |
| æ–‡æœ¬â†’å›¾åƒ | 78% | â­â­â­â­ |
| å›¾åƒâ†’æ–‡æœ¬ | 82% | â­â­â­â­â­ |
| è·¨æ¨¡æ€ç”Ÿæˆ | 75% | â­â­â­ |

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## ğŸ™ è‡´è°¢

- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [PyTorch](https://pytorch.org/)
- [OpenAI GPTç³»åˆ—æ¨¡å‹](https://openai.com/research/gpt)

---

**æ³¨æ„**: æœ¬é¡¹ç›®ä¸ºç ”ç©¶åŸå‹ï¼Œå®é™…åº”ç”¨éœ€æ ¹æ®å…·ä½“åœºæ™¯è°ƒæ•´å‚æ•°å’Œè®­ç»ƒæ•°æ®ã€‚